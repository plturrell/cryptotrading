# Production Model Serving Infrastructure

This document describes the production-ready ML model serving infrastructure built for Vercel deployment with **full model quality preservation**.

## üèóÔ∏è Architecture Overview

### Components

1. **Model Registry** (`model_server.py`)
   - Versioned model storage
   - Automatic best version selection
   - In-memory caching with LRU eviction
   - Metadata tracking

2. **Model Storage** (`model_storage.py`)
   - Vercel Blob integration for production
   - Local file storage for development
   - Automatic versioning
   - Model lifecycle management

3. **Model Serving API** (`model_server.py`)
   - Production-grade prediction queue
   - Request-level caching
   - Performance tracking
   - Async processing

4. **Performance Tracker** (`model_server.py`)
   - Real-time performance metrics
   - Prediction accuracy tracking
   - Latency monitoring
   - Error rate tracking

## üöÄ Key Features

### 1. Full Model Quality Preservation
```python
# Models are stored as complete sklearn objects
model_data = pickle.dumps(full_sklearn_model)
await registry.register_model(model_id, model_data, metadata)
```

### 2. Automatic Version Management
```python
# Best performing model is automatically selected
model = await registry.get_model("BTC")  # Gets best version
model = await registry.get_model("BTC", "v1.2.3")  # Specific version
```

### 3. Production-Grade Caching
- Prediction results cached for 5 minutes
- Model instances cached in memory
- Automatic cache invalidation

### 4. Real Performance Tracking
```python
# Track predictions
await tracker.track_prediction(model_id, prediction_result)

# Track actual outcomes for accuracy
await tracker.track_actual_outcome(model_id, prediction_id, predicted, actual)
```

## üì° API Endpoints

### 1. Model Training
```bash
POST /api/ml/train
{
  "model_id": "BTC"
}

# Response includes training request ID
GET /api/ml/train/status?request_id=xxx
```

### 2. Model Serving (Full Quality)
```bash
POST /api/ml/serve
{
  "symbol": "BTC",
  "horizon": "24h"
}
```

### 3. Batch Predictions
```bash
POST /api/ml/batch
{
  "symbols": ["BTC", "ETH"],
  "horizon": "24h"
}
```

### 4. Performance Monitoring
```bash
GET /api/ml/performance/BTC

POST /api/ml/performance/track
{
  "model_id": "BTC",
  "prediction_id": "xxx",
  "predicted_value": 51000,
  "actual_value": 50500
}
```

## üîß Deployment Process

### 1. Train Models Locally
```bash
python scripts/train_models.py
```

### 2. Deploy Models to Vercel
```bash
python scripts/deploy_models_to_vercel.py
```

### 3. Deploy to Production
```bash
vercel --prod
```

### 4. Set Environment Variables
In Vercel Dashboard:
- `VERCEL_BLOB_READ_WRITE_TOKEN`: Your Vercel Blob token
- `ML_MODELS_CONFIG`: Auto-generated by deployment script

## üèÉ Performance Characteristics

### Latency
- First prediction: ~2-3s (model loading)
- Cached predictions: <50ms
- Batch predictions: Parallel processing

### Scalability
- Models cached across requests
- Queue-based processing
- Automatic scaling with Vercel

### Reliability
- Automatic retries
- Graceful degradation
- Error tracking

## üîç Model Quality Metrics

### Training Metrics
- R¬≤ Score: Model accuracy (0-1)
- MAPE: Mean Absolute Percentage Error
- Feature importance tracking

### Production Metrics
- Prediction latency
- Cache hit rate
- Error rate
- Model version performance

## üõ°Ô∏è Error Handling

1. **No Model Available**: Returns 503 with clear error
2. **Data Fetch Failed**: Returns 503 with market data error
3. **Prediction Timeout**: Returns timeout error after 30s
4. **Invalid Features**: Returns 400 with validation error

## üìä Monitoring

### Real-time Metrics
```javascript
// Frontend integration
const performance = await fetch('/api/ml/performance/BTC');
const metrics = await performance.json();

console.log('Model accuracy:', metrics.avg_error_pct);
console.log('Total predictions:', metrics.predictions_total);
```

### Daily Model Retraining
Configured in `vercel.json`:
```json
"crons": [{
  "path": "/api/ml/train",
  "schedule": "0 6 * * *"
}]
```

## üîÑ Model Lifecycle

1. **Training**: Models trained with real Yahoo Finance data
2. **Registration**: Versioned storage with metadata
3. **Deployment**: Automatic best version selection
4. **Monitoring**: Real-time performance tracking
5. **Retraining**: Automated daily updates

## üí° Best Practices

1. **Always use real data** - No dummy values
2. **Monitor performance** - Track prediction accuracy
3. **Version models** - Keep model history
4. **Cache aggressively** - Reduce latency
5. **Fail gracefully** - Clear error messages

## üö® Troubleshooting

### "No trained model available"
- Run deployment script: `python scripts/deploy_models_to_vercel.py`
- Check Vercel Blob token is set

### "Unable to fetch market data"
- Verify Yahoo Finance is accessible
- Check symbol format (BTC, ETH, etc.)

### High latency
- Check cache configuration
- Monitor model size
- Review feature calculation

This infrastructure ensures **100% model quality preservation** while maintaining excellent performance on Vercel's edge network.